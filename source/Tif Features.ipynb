{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on https://www.kaggle.com/the1owl/fractals-of-nature-blend-0-90050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import fbeta_score\n",
    "from PIL import Image, ImageStat\n",
    "from skimage import io\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, cv2\n",
    "import random\n",
    "import scipy\n",
    "import os\n",
    "import bcolz\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    # fbeta_score throws a confusing error if inputs are not numpy arrays\n",
    "    y_true, y_pred, = np.array(y_true), np.array(y_pred)\n",
    "    # We need to use average='samples' here, any other average method will generate bogus results\n",
    "    return fbeta_score(y_true, y_pred, beta=2, average='samples')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(path):\n",
    "    try:\n",
    "        st = []\n",
    "        #pillow jpg\n",
    "        img = Image.open(path)\n",
    "        im_stats_ = ImageStat.Stat(img)\n",
    "        st += im_stats_.sum\n",
    "        st += im_stats_.mean\n",
    "        st += im_stats_.rms\n",
    "        st += im_stats_.var\n",
    "        st += im_stats_.stddev\n",
    "        img = np.array(img)[:,:,:3]\n",
    "        st += [scipy.stats.kurtosis(img[:,:,0].ravel())]\n",
    "        st += [scipy.stats.kurtosis(img[:,:,1].ravel())]\n",
    "        st += [scipy.stats.kurtosis(img[:,:,2].ravel())]\n",
    "        st += [scipy.stats.skew(img[:,:,0].ravel())]\n",
    "        st += [scipy.stats.skew(img[:,:,1].ravel())]\n",
    "        st += [scipy.stats.skew(img[:,:,2].ravel())]\n",
    "        #cv2 jpg\n",
    "        img = cv2.imread(path)\n",
    "        bw = cv2.imread(path,0)\n",
    "        st += list(cv2.calcHist([bw],[0],None,[256],[0,256]).flatten()) #bw \n",
    "        st += list(cv2.calcHist([img],[0],None,[256],[0,256]).flatten()) #r\n",
    "        st += list(cv2.calcHist([img],[1],None,[256],[0,256]).flatten()) #g\n",
    "        st += list(cv2.calcHist([img],[2],None,[256],[0,256]).flatten()) #b\n",
    "        try:\n",
    "            #skimage tif\n",
    "            p1 = path.replace('jpg','tif')\n",
    "            p1 = p1.replace('train-tif','train-tif-v2') #Why make path changes so complex that they nullify old scripts\n",
    "            p1 = p1.replace('test-tif','test-tif-v2') #Why make path changes so complex that they nullify old scripts\n",
    "            imgr = io.imread(p1)\n",
    "            tf = imgr[:, :, 3]\n",
    "            st += list(cv2.calcHist([tf],[0],None,[256],[0,65536]).flatten()) #near ifrared\n",
    "            ndvi = ((imgr[:, :, 3] - imgr[:, :, 0]) / (imgr[:, :, 3] + imgr[:, :, 0])) #water ~ -1.0, barren area ~ 0.0, shrub/grass ~ 0.2-0.4, forest ~ 1.0\n",
    "            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n",
    "            ndvi = ((imgr[:, :, 3] - imgr[:, :, 1]) / (imgr[:, :, 3] + imgr[:, :, 1]))\n",
    "            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n",
    "            ndvi = ((imgr[:, :, 3] - imgr[:, :, 2]) / (imgr[:, :, 3] + imgr[:, :, 2]))\n",
    "            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n",
    "        except:\n",
    "            st += [-1 for i in range(256)]\n",
    "            st += [-2 for i in range(60)]\n",
    "            p1 = path.replace('jpg','tif')\n",
    "            p1 = p1.replace('train-tif','train-tif-v2') #Why make path changes so complex that they nullify old scripts\n",
    "            p1 = p1.replace('test-tif','test-tif-v2') #Why make path changes so complex that they nullify old scripts\n",
    "            print('err', p1)\n",
    "        m, s = cv2.meanStdDev(img) #mean and standard deviation\n",
    "        st += list(m)\n",
    "        st += list(s)\n",
    "        st += [cv2.Laplacian(bw, cv2.CV_64F).var()] \n",
    "        st += [cv2.Laplacian(img, cv2.CV_64F).var()]\n",
    "        st += [cv2.Sobel(bw,cv2.CV_64F,1,0,ksize=5).var()]\n",
    "        st += [cv2.Sobel(bw,cv2.CV_64F,0,1,ksize=5).var()]\n",
    "        st += [cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5).var()]\n",
    "        st += [cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5).var()]\n",
    "        st += [(bw<30).sum()]\n",
    "        st += [(bw>225).sum()]\n",
    "    except:\n",
    "        print(path)\n",
    "    return [path, st]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_img(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(get_features, paths)\n",
    "    for i in range(len(ret)):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "    ret = []\n",
    "    fdata = [imf_d[f] for f in paths]\n",
    "    return fdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_path = 'data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('data/train_v2.csv')\n",
    "df_test = pd.read_csv('data/sample_submission_v2.csv')\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'cultivation',\n",
    " 'artisinal_mine',\n",
    " 'haze',\n",
    " 'primary',\n",
    " 'slash_burn',\n",
    " 'habitation',\n",
    " 'clear',\n",
    " 'road',\n",
    " 'selective_logging',\n",
    " 'partly_cloudy',\n",
    " 'agriculture',\n",
    " 'water',\n",
    " 'cloudy']\n",
    "\n",
    "label_map = {'agriculture': 14,\n",
    " 'artisinal_mine': 5,\n",
    " 'bare_ground': 1,\n",
    " 'blooming': 3,\n",
    " 'blow_down': 0,\n",
    " 'clear': 10,\n",
    " 'cloudy': 16,\n",
    " 'conventional_mine': 2,\n",
    " 'cultivation': 4,\n",
    " 'habitation': 9,\n",
    " 'haze': 6,\n",
    " 'partly_cloudy': 13,\n",
    " 'primary': 7,\n",
    " 'road': 11,\n",
    " 'selective_logging': 12,\n",
    " 'slash_burn': 8,\n",
    " 'water': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d3557a86654d478c6509abe956cc2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for f, tags in tqdm_notebook(df_train.values, miniters=1000):\n",
    "    targets = np.zeros(17)\n",
    "    \n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "        \n",
    "\n",
    "    y_train.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = pd.read_csv(in_path + 'train_v2.csv')\n",
    "x_dev['path'] = x_dev['image_name'].map(lambda x: in_path + 'train-jpg/' + x + '.jpg')\n",
    "# y_train = x_dev['tags'].str.get_dummies(sep=' ')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "random.seed(3)\n",
    "np.random.seed(3)\n",
    "\n",
    "perm = np.random.permutation(len(x_dev))\n",
    "idx_train = perm[:int(len(x_dev)*(1-VALIDATION_SPLIT))]\n",
    "idx_val = perm[int(len(x_dev)*(1-VALIDATION_SPLIT)):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3543"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6658,  1687, 19366, ..., 11513,  1688,  5994])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_dev.iloc[idx_train]\n",
    "Y_train = y_train[idx_train]\n",
    "\n",
    "X_valid = x_dev.iloc[idx_val]\n",
    "Y_valid = y_train[idx_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train.iloc[0].values,Y_train.iloc[10].values,Y_train.iloc[200].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int8))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y_valid.iloc[0].values,Y_valid.iloc[10].values,Y_valid.iloc[200].values\n",
    "\n",
    "Y_valid[0],Y_valid[10],Y_valid[2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_feats = normalize_img(X_train['path'])\n",
    "# X_valid_feats = normalize_img(X_valid['path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_array(\"data/cache/X_train_feats_xgb.dat\",np.array(X_train_feats))\n",
    "# save_array(\"data/cache/X_valid_feats_xgb.dat\",np.array(X_valid_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_feats = load_array(\"data/cache/X_train_feats_xgb.dat\")\n",
    "X_valid_feats = load_array(\"data/cache/X_valid_feats_xgb.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_jpg = glob.glob(in_path + 'test-jpg/*')\n",
    "test = pd.DataFrame([[p.split('/')[-1].replace('.jpg',''),p] for p in test_jpg])\n",
    "test.columns = ['image_name','path']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_test_feats = normalize_img(test['path']); \n",
    "# save_array(\"data/cache/X_test_feats_xgb.dat\",np.array(x_test_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_feats = load_array(\"data/cache/X_test_feats_xgb.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgb_train = pd.DataFrame(X_train[['path']], columns=['path'])\n",
    "# xgb_valid = pd.DataFrame(X_valid[['image_name']], columns=['image_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for c in y.columns:\n",
    "#     model = xgb.XGBClassifier(n_estimators=200, learning_rate=0.3, max_depth=4, seed=1, base_score=0.5)\n",
    "#     model.fit(np.array(xtrain), y[c])\n",
    "#     xgb_train[c] = model.predict_proba(np.array(xtrain))[:, 1]\n",
    "#     xgb_test[c] = model.predict_proba(np.array(xtest))[:, 1]\n",
    "#     print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = np.zeros((X_valid.shape[0], 17)).astype(np.float32)\n",
    "test_preds = np.zeros((x_test_feats.shape[0], 17)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32383, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.values[:, 1].reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "xgb_params = {'colsample_bylevel':0.9,\n",
    " 'colsample_bytree': 0.9,\n",
    " 'eval_metric': 'logloss',\n",
    " 'gamma': 1.,#0.02933179779163947,\n",
    " 'learning_rate': 0.1,#8244194429306306,\n",
    " 'max_depth': 5,\n",
    " 'n_estimators': 200,\n",
    " 'objective': 'binary:logistic',\n",
    " 'reg_alpha': 0.0003,#0.14600953461910307,\n",
    " 'reg_lambda': 1,#1.0750571669994455,\n",
    " 'scale_pos_weight': 1,\n",
    " 'subsample': 0.9, #0.8097993636153147, \n",
    "             'nthread':4,'silent':1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff879880f03f4c94b7d7b0313df2249f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.641223\tvalid-logloss:0.642913\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "\n",
      "[20]\ttrain-logloss:0.327921\tvalid-logloss:0.352553\n",
      "[40]\ttrain-logloss:0.275462\tvalid-logloss:0.313537\n",
      "[60]\ttrain-logloss:0.255177\tvalid-logloss:0.303773\n",
      "[80]\ttrain-logloss:0.241647\tvalid-logloss:0.298754\n",
      "[100]\ttrain-logloss:0.229544\tvalid-logloss:0.294668\n",
      "[120]\ttrain-logloss:0.221216\tvalid-logloss:0.292861\n",
      "[140]\ttrain-logloss:0.214124\tvalid-logloss:0.291121\n",
      "[160]\ttrain-logloss:0.205627\tvalid-logloss:0.289588\n",
      "[180]\ttrain-logloss:0.198627\tvalid-logloss:0.288904\n",
      "[200]\ttrain-logloss:0.19157\tvalid-logloss:0.288247\n",
      "[220]\ttrain-logloss:0.18538\tvalid-logloss:0.287848\n",
      "[240]\ttrain-logloss:0.179043\tvalid-logloss:0.287279\n",
      "[260]\ttrain-logloss:0.173169\tvalid-logloss:0.287113\n",
      "[280]\ttrain-logloss:0.168179\tvalid-logloss:0.286841\n",
      "[300]\ttrain-logloss:0.16272\tvalid-logloss:0.286554\n",
      "[320]\ttrain-logloss:0.157491\tvalid-logloss:0.286309\n",
      "[340]\ttrain-logloss:0.152065\tvalid-logloss:0.285944\n",
      "[360]\ttrain-logloss:0.146873\tvalid-logloss:0.285388\n",
      "[380]\ttrain-logloss:0.143068\tvalid-logloss:0.285577\n",
      "[400]\ttrain-logloss:0.138879\tvalid-logloss:0.285222\n",
      "[420]\ttrain-logloss:0.134553\tvalid-logloss:0.285589\n",
      "[440]\ttrain-logloss:0.130609\tvalid-logloss:0.285079\n",
      "[460]\ttrain-logloss:0.127757\tvalid-logloss:0.285449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-e0eaffd2c5d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#               early_stopping_rounds=50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,feval=kappa)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for class_i in tqdm_notebook(range(17), miniters=1): \n",
    "    \n",
    "    d_train = xgb.DMatrix(X_train_feats,label= Y_train.values[:, class_i])#, weight=weight_train)\n",
    "    d_valid = xgb.DMatrix(X_valid_feats,label= Y_valid.values[:,class_i])#,weight=weight_val)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "#     model = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=200, \\\n",
    "#                               silent=True, objective='binary:logistic', nthread=-1, \\\n",
    "#                               gamma=0, min_child_weight=1, max_delta_step=0, \\\n",
    "#                               subsample=1, colsample_bytree=1, colsample_bylevel=1, \\\n",
    "#                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \\\n",
    "#                               base_score=0.5, seed=random_seed, missing=None)\n",
    "    \n",
    "#     model.fit(X_train_feats, Y_train.values[:, class_i],\n",
    "#               eval_set=[(X_valid_feats,Y_valid.values[:,class_i])],\n",
    "#               early_stopping_rounds=50)\n",
    "    \n",
    "    bst = xgb.train(xgb_params, d_train, 1000,  watchlist, early_stopping_rounds=50, verbose_eval=20)#,feval=kappa)\n",
    " \n",
    "\n",
    "\n",
    "    models.append(bst)\n",
    "#     test_preds[:, class_i] = model.predict_proba(x_test_feats)[:, 1]\n",
    "    val_preds[:, class_i] = bst.predict(X_valid_feats)#[:, 1]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {'colsample_bylevel':0.9086627943049572,\n",
    " 'colsample_bytree': 0.8662812861700129,\n",
    " 'eval_metric': 'logloss',\n",
    " 'gamma': 1.,#0.02933179779163947,\n",
    " 'learning_rate': 0.07,#8244194429306306,\n",
    " 'max_depth': 9,\n",
    " 'n_estimators': 3500,\n",
    " 'objective': 'binary:logistic',\n",
    " 'reg_alpha': 0.0003,#0.14600953461910307,\n",
    " 'reg_lambda': 50,#1.0750571669994455,\n",
    " 'scale_pos_weight': 1,\n",
    " 'subsample': 0.8, #0.8097993636153147, \n",
    "             'nthread':16,'silent':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# with open('data/cache/models_xgb_v1.dump','w') as f:\n",
    "#     pickle.dump(models,f,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(\"data/cache/xgb_tiffeatures_valpreds.dat\",val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimise_f2_thresholds2(y, p, verbose=True, resolution=100,num_classes=17):\n",
    "    def mf(x):\n",
    "        p2 = np.zeros_like(p)\n",
    "        for i in range(num_classes):\n",
    "            p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n",
    "        score = fbeta_score(y, p2, beta=2, average='samples')\n",
    "        return score\n",
    "\n",
    "    x = [0.1]*num_classes\n",
    "    for i in range(num_classes):\n",
    "        best_i2 = 0\n",
    "        best_score = 0\n",
    "        for i2 in range(resolution):\n",
    "            threshold = float(i2) / resolution\n",
    "            x[i] = threshold\n",
    "            score = mf(x)\n",
    "            if score > best_score:\n",
    "                best_i2 = threshold\n",
    "                best_score = score\n",
    "\n",
    "        x[i] = best_i2\n",
    "        if verbose:\n",
    "            print(i, best_i2, best_score)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.23, 0.88783326343960201)\n",
      "(1, 0.03, 0.88790427213724354)\n",
      "(2, 0.09, 0.88791310683440661)\n",
      "(3, 0.24, 0.88815583364949491)\n",
      "(4, 0.09, 0.88818230174661505)\n",
      "(5, 0.26, 0.88883928653794697)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0.07, 0.88907421041253543)\n",
      "(7, 0.08, 0.88908418610297935)\n",
      "(8, 0.19, 0.89107040177114327)\n",
      "(9, 0.24, 0.89208064637974616)\n",
      "(10, 0.19, 0.89271746682132724)\n",
      "(11, 0.22, 0.89335880601464446)\n",
      "(12, 0.18, 0.8938089693602661)\n",
      "(13, 0.18, 0.89588005480579713)\n",
      "(14, 0.18, 0.89609137014983664)\n",
      "(15, 0.18, 0.89614661156096986)\n",
      "(16, 0.19, 0.89849350651529125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16705882352941179"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thres = optimise_f2_thresholds2(Y_valid, val_preds,num_classes=17)\n",
    "\n",
    "np.mean(thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('F2 Score:', 0.89849350651529125)\n"
     ]
    }
   ],
   "source": [
    "print('F2 Score:', f2_score(Y_valid, val_preds>thres)) #combined_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
